{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过滤后的数据已保存到: /workspaces/SFP/validation_data/filtered_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "file_path = '/workspaces/SFP/Training_data/data_13_17_1_std.csv'  # 请替换为你的CSV文件路径\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 将 'postime' 列解析为日期时间格式\n",
    "df['postime'] = pd.to_datetime(df['postime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# 提取日期和小时\n",
    "df['date'] = df['postime'].dt.date\n",
    "df['hour'] = df['postime'].dt.hour\n",
    "\n",
    "# 初始化一个空的 DataFrame 用于存储结果\n",
    "filtered_df = pd.DataFrame()\n",
    "\n",
    "# 按 num（船编号）分组\n",
    "for num, group in df.groupby('num'):\n",
    "    # 检查每个日期是否包含完整的 0-23 小时\n",
    "    complete_dates = group.groupby('date')['hour'].apply(lambda x: len(set(x)) == 24 and set(x) == set(range(24)))\n",
    "    valid_dates = complete_dates[complete_dates].index  # 提取满足条件的日期\n",
    "\n",
    "    # 筛选出完整日期的数据\n",
    "    filtered_group = group[group['date'].isin(valid_dates)]\n",
    "\n",
    "    # 将筛选后的数据添加到结果 DataFrame\n",
    "    filtered_df = pd.concat([filtered_df, filtered_group], ignore_index=True)\n",
    "\n",
    "# 删除辅助列\n",
    "filtered_df = filtered_df.drop(columns=['date', 'hour'])\n",
    "\n",
    "# 保存结果为新的CSV文件\n",
    "output_file = '/workspaces/SFP/validation_data/filtered_data.csv'\n",
    "filtered_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"过滤后的数据已保存到: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation for fuel consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [13:01:59] WARNING: /workspace/src/collective/../data/../common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/codespace/.python/current/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator VotingRegressor from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from class_calm_water_resistance_estimatoin import *\n",
    "\n",
    "\n",
    "def Rtotal2Pe(row):\n",
    "    \"\"\"\"\n",
    "\n",
    "    每一行反算R_total函数\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    cu = row['stream_val']*np.sin(np.deg2rad(row['stream_direction']))\n",
    "    cv = row['stream_val']*np.cos(np.deg2rad(row['stream_direction']))\n",
    "    sog = row['SOG']*0.5144 # knot to m/s\n",
    "    r_total = row['R_t_pre']\n",
    "    heading_ship = row['heading']\n",
    "    V_water = speedGPS2Water(sog, heading_ship, cu, cv) \n",
    "    Pe = V_water*r_total\n",
    "\n",
    "    return Pe # 单位千牛\n",
    "\n",
    "\n",
    "def calFuelHour(row):\n",
    "    etaR = 1.0 # 准确计算较复杂，但整体波动小，经验值是1-1.07或者0.98\n",
    "    etaO = 0.60 # 可以算，但需要知道V_A和thruster force T的具体意义，经验值0.55-0.7\n",
    "    etaS = 0.99 # 无计算公式，取经验值，0.99，0.98，0.95-0.96三种情况\n",
    "    etaH = 1.1 # 要计算t, w，1-t/1-w,需要知道力和速度的关系。\n",
    "    SOFC = 200 # g/kwh\n",
    "    eta = etaR*etaO*etaS*etaH\n",
    "\n",
    "    P = row['P_pre']\n",
    "    fuel_hour = P/eta*SOFC/1000000\n",
    "\n",
    "    return fuel_hour\n",
    "\n",
    "# 读取 CSV 文件\n",
    "file_path = '/workspaces/SFP/validation_data/filtered_data.csv'  # 替换为你的 CSV 文件路径\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 提取指定列\n",
    "columns_to_use = [\n",
    "    'SOG', 'heading', 'draught', 'wind_val', 'wind_direction',\n",
    "    'wave_val', 'wave_direction', 'stream_val', 'stream_direction'\n",
    "]\n",
    "input_df = df[columns_to_use]\n",
    "\n",
    "# 加载预训练的集成模型\n",
    "with open('ensemble_model.pkl', 'rb') as file:\n",
    "    ensemble_model = pickle.load(file)\n",
    "\n",
    "# 数据预处理（标准化）\n",
    "feature_scaler = StandardScaler()\n",
    "input_features_scaled = feature_scaler.fit_transform(input_df)\n",
    "\n",
    "# 进行预测\n",
    "df['R_a_pre'] = ensemble_model.predict(input_features_scaled)\n",
    "\n",
    "# 计算 R_t_pre 列：R_a_pre 和 R_calm 的和\n",
    "df['R_t_pre'] = df['R_a_pre'] + df['R_calm']\n",
    "\n",
    "# 计算 P_pre 列\n",
    "df['P_pre'] = df.apply(Rtotal2Pe, axis=1)\n",
    "\n",
    "# 计算 P_pre 列\n",
    "df['Fuel_hour'] = df.apply(calFuelHour, axis=1)\n",
    "\n",
    "# 提取日期（去掉时间部分）\n",
    "df['date'] = pd.to_datetime(df['postime']).dt.date\n",
    "\n",
    "# 按日期汇总 Fuel_hour\n",
    "# 按 num 和 date 分组计算每天的 Fuel_hour\n",
    "grouped = df.groupby(['num', 'date']).agg(\n",
    "    Fuel_hour=('Fuel_hour', 'sum')  # 汇总每天的 Fuel_hour\n",
    ").reset_index()\n",
    "\n",
    "# 按 num 排序，然后在每个 num 内部按日期排序\n",
    "grouped = grouped.sort_values(by=['num', 'date']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "grouped.to_csv('/workspaces/SFP/validation_data/predicted_day.csv')\n",
    "# 保存结果为新的 CSV 文件\n",
    "# output_file = 'daily_fuel_hour.csv'\n",
    "# daily_fuel_hour.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# print(f\"统计完成，每日的燃料消耗量已保存到: {output_file}\")\n",
    "\n",
    "# # 保存结果为新的 CSV 文件\n",
    "# output_file = '/workspaces/SFP/validation_data/predicted.csv'\n",
    "# df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# print(f\"预测完成，结果已保存到: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fuel = pd.read_csv('/workspaces/SFP/raw_data/mrv.csv')\n",
    "\n",
    "\n",
    "# 确保日期格式一致\n",
    "grouped['date'] = pd.to_datetime(grouped['date']).dt.date  # 保留日期部分\n",
    "df_fuel['input_date'] = pd.to_datetime(df_fuel['input_date']).dt.date  # 保留日期部分\n",
    "\n",
    "# 合并数据，按 'num' 和日期匹配\n",
    "merged_df = pd.merge(\n",
    "    grouped, \n",
    "    df_fuel, \n",
    "    left_on=['num', 'date'], \n",
    "    right_on=['num', 'input_date'], \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# 删除重复的日期列，只保留一个\n",
    "merged_df = merged_df.rename(columns={'date': 'merged_date', 'Fuel_hour': 'Predict_fuel'})\n",
    "final_df = merged_df[['num', 'merged_date', 'Predict_fuel', 'daily_fuel_mrv']]\n",
    "\n",
    "\n",
    "final_df.to_csv('/workspaces/SFP/validation_data/final_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
