{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成文件 2.csv 的补全并保存到 /workspaces/SFP/test_trajectory/completed_trajectory\n",
      "完成文件 5.csv 的补全并保存到 /workspaces/SFP/test_trajectory/completed_trajectory\n",
      "完成文件 1.csv 的补全并保存到 /workspaces/SFP/test_trajectory/completed_trajectory\n",
      "完成文件 6.csv 的补全并保存到 /workspaces/SFP/test_trajectory/completed_trajectory\n",
      "完成文件 0.csv 的补全并保存到 /workspaces/SFP/test_trajectory/completed_trajectory\n",
      "完成文件 3.csv 的补全并保存到 /workspaces/SFP/test_trajectory/completed_trajectory\n",
      "完成文件 4.csv 的补全并保存到 /workspaces/SFP/test_trajectory/completed_trajectory\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def average_every_n_points(df, chunk_size=60, output_path=None):\n",
    "    \"\"\"\n",
    "    对数据按指定的行数分块取平均，最终确保 DataFrame 记录数为 24 条。\n",
    "    \n",
    "    参数：\n",
    "        df (DataFrame): 输入的数据框。\n",
    "        chunk_size (int): 每多少行取一次平均，默认值为 60。\n",
    "        output_path (str): 输出 CSV 文件路径，如果为 None，则不保存文件。\n",
    "    \n",
    "    返回：\n",
    "        averaged_df (DataFrame): 每块数据的平均值组成的 DataFrame，最终包含 24 条记录。\n",
    "    \"\"\"\n",
    "    # 每 chunk_size 行取平均\n",
    "    averaged_data = []\n",
    "    for i in range(0, len(df), chunk_size):\n",
    "        # 获取当前块的数据\n",
    "        chunk = df.iloc[i:i + chunk_size]\n",
    "        # 对块取平均值\n",
    "        chunk_mean = chunk.mean()\n",
    "        # 添加到结果列表\n",
    "        averaged_data.append(chunk_mean)\n",
    "    \n",
    "    # 生成新的 DataFrame\n",
    "    averaged_df = pd.DataFrame(averaged_data)\n",
    "    \n",
    "    # 调整到 24 条记录\n",
    "    if len(averaged_df) > 24:\n",
    "        # 如果多于 24 条，截取前 24 条\n",
    "        averaged_df = averaged_df.iloc[:24]\n",
    "    elif len(averaged_df) < 24:\n",
    "        # 如果少于 24 条，复制最后一行补齐\n",
    "        last_row = averaged_df.iloc[-1:]  # 取最后一行\n",
    "        rows_to_add = 24 - len(averaged_df)  # 计算需要补充的行数\n",
    "        averaged_df = pd.concat([averaged_df, pd.concat([last_row] * rows_to_add, ignore_index=True)], ignore_index=True)\n",
    "    \n",
    "    # 如果指定了输出路径，保存文件\n",
    "    if output_path:\n",
    "        averaged_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    return averaged_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 文件夹路径\n",
    "simulation_ais_folder = \"/workspaces/SFP/test_trajectory/Simulation_AIS\"\n",
    "trajectorylib_folder = \"/workspaces/SFP/test_trajectory/trajectorylib\"\n",
    "output_folder = \"/workspaces/SFP/test_trajectory/completed_trajectory\"\n",
    "\n",
    "# 创建输出文件夹\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# 遍历 Simulation AIS 文件夹中的文件\n",
    "for simulation_file in os.listdir(simulation_ais_folder):\n",
    "    if simulation_file.endswith(\".csv\"):\n",
    "        # 获取文件序号\n",
    "        file_num = os.path.splitext(simulation_file)[0]\n",
    "\n",
    "        # 读取 Simulation AIS 数据\n",
    "        simulation_path = os.path.join(simulation_ais_folder, simulation_file)\n",
    "        simulation_data = pd.read_csv(simulation_path)\n",
    "        simulation_data = average_every_n_points(simulation_data, chunk_size=60, output_path=None)\n",
    "\n",
    "        # 读取对应的原始轨迹文件\n",
    "        trajectory_file = f\"{file_num}_\"  # 匹配前缀\n",
    "        trajectory_path = None\n",
    "        for traj_file in os.listdir(trajectorylib_folder):\n",
    "            if traj_file.startswith(trajectory_file) and traj_file.endswith(\".csv\"):\n",
    "                trajectory_path = os.path.join(trajectorylib_folder, traj_file)\n",
    "                break\n",
    "\n",
    "        if trajectory_path is None:\n",
    "            print(f\"未找到与 {simulation_file} 对应的原始轨迹文件。\")\n",
    "            continue\n",
    "\n",
    "        # 读取原始轨迹数据\n",
    "        trajectory_data = pd.read_csv(trajectory_path)\n",
    "\n",
    "        # 检查需要补全的列是否存在\n",
    "        required_columns = [\n",
    "            'draught', 'wind_val', 'wind_direction',\n",
    "            'wave_val', 'wave_direction', 'stream_val', 'stream_direction'\n",
    "        ]\n",
    "        if not all(col in trajectory_data.columns for col in required_columns):\n",
    "            print(f\"原始轨迹文件 {trajectory_path} 缺少必要的列。\")\n",
    "            continue\n",
    "\n",
    "        # 补全数据\n",
    "        completed_data = simulation_data.copy()\n",
    "        for idx, row in simulation_data.iterrows():\n",
    "            # 计算原始轨迹中与当前点最接近的点\n",
    "            distances = np.sqrt((trajectory_data['lon'] - row['lon'])**2 +\n",
    "                                (trajectory_data['lat'] - row['lat'])**2)\n",
    "            closest_idx = distances.idxmin()\n",
    "\n",
    "            # 获取最接近点的数据并补全\n",
    "            for col in required_columns:\n",
    "                completed_data.loc[idx, col] = trajectory_data.loc[closest_idx, col]\n",
    "\n",
    "        # 保存补全后的文件\n",
    "        output_path = os.path.join(output_folder, f\"{file_num}.csv\")\n",
    "        completed_data.to_csv(output_path, index=False)\n",
    "\n",
    "        print(f\"完成文件 {file_num}.csv 的补全并保存到 {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_calm_water_resistance_estimatoin import *\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def Cal_R_calm(row):\n",
    "    heading_ship = row['heading']\n",
    "    cu = row['stream_val']*np.sin(np.deg2rad(row['stream_direction']))\n",
    "    cv = row['stream_val']*np.cos(np.deg2rad(row['stream_direction']))\n",
    "    sog = row['SOG']*0.5144\n",
    "\n",
    "    V_water = speedGPS2Water(sog, heading_ship, cu, cv)\n",
    "    V_shallow=V_water\n",
    "    r_calm = calm_water_resistance(V_shallow)\n",
    "\n",
    "    return r_calm/1000\n",
    "\n",
    "def Rtotal2Pe(row):\n",
    "    \"\"\"\"\n",
    "\n",
    "    每一行反算R_total函数\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    cu = row['stream_val']*np.sin(np.deg2rad(row['stream_direction']))\n",
    "    cv = row['stream_val']*np.cos(np.deg2rad(row['stream_direction']))\n",
    "    sog = row['SOG']*0.5144 # knot to m/s\n",
    "    r_total = row['R_t_pre']\n",
    "    heading_ship = row['heading']\n",
    "    V_water = speedGPS2Water(sog, heading_ship, cu, cv) \n",
    "    Pe = V_water*r_total\n",
    "\n",
    "    return Pe # 单位千牛\n",
    "\n",
    "def calFuelHour(row):\n",
    "    etaR = 1.0 # 准确计算较复杂，但整体波动小，经验值是1-1.07或者0.98\n",
    "    etaO = 0.60 # 可以算，但需要知道V_A和thruster force T的具体意义，经验值0.55-0.7\n",
    "    etaS = 0.99 # 无计算公式，取经验值，0.99，0.98，0.95-0.96三种情况\n",
    "    etaH = 1.1 # 要计算t, w，1-t/1-w,需要知道力和速度的关系。\n",
    "    SOFC = 200 # g/kwh\n",
    "    eta = etaR*etaO*etaS*etaH\n",
    "\n",
    "    P = row['P_pre']\n",
    "    fuel_hour = P/eta*SOFC/1000000\n",
    "\n",
    "    return fuel_hour\n",
    "\n",
    "\n",
    "def calFuelMinute(row):\n",
    "    \"\"\"\n",
    "    计算每分钟的燃油消耗率\n",
    "    输入:\n",
    "        row - 数据行，包含 'P_pre'（功率值，单位：kW）\n",
    "    输出:\n",
    "        fuel_minute - 每分钟的燃油消耗率（单位：吨/分钟）\n",
    "    \"\"\"\n",
    "    # 各种效率参数\n",
    "    etaR = 1.0  # 整体波动效率\n",
    "    eta0 = 0.60  # 螺旋桨效率\n",
    "    etaS = 0.99  # 联轴器效率\n",
    "    etaH = 1.1  # 波浪影响效率\n",
    "    SOFC = 200  # 燃油消耗率，单位：g/kWh\n",
    "\n",
    "    # 总效率计算\n",
    "    eta = etaR * eta0 * etaS * etaH\n",
    "\n",
    "    # 获取功率值\n",
    "    P = row['P_pre']\n",
    "\n",
    "    # 每小时的燃油消耗率 (吨/小时)\n",
    "    fuel_hour = P / eta * SOFC / 1000000\n",
    "\n",
    "    # 转换为每分钟的燃油消耗率 (吨/分钟)\n",
    "    fuel_minute = fuel_hour / 60\n",
    "\n",
    "    return fuel_minute\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数字船的数据并计算各种阻力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.60864205292896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator VotingRegressor from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('/workspaces/SFP/test_trajectory/completed_trajectory/5.csv')\n",
    "\n",
    "# df = average_every_n_points(df, chunk_size=60, output_path=None)\n",
    "\n",
    "df['R_calm'] = df.apply(Cal_R_calm, axis=1) # KN\n",
    "\n",
    "columns_to_use = [\n",
    "    'SOG', 'heading', 'draught', 'wind_val', 'wind_direction',\n",
    "    'wave_val', 'wave_direction', 'stream_val', 'stream_direction'\n",
    "]\n",
    "input_df = df[columns_to_use]\n",
    "\n",
    "# 加载预训练的集成模型\n",
    "with open('ensemble_model.pkl', 'rb') as file:\n",
    "    ensemble_model = pickle.load(file)\n",
    "\n",
    "# 数据预处理（标准化）\n",
    "feature_scaler = StandardScaler()\n",
    "input_features_scaled = feature_scaler.fit_transform(input_df)\n",
    "\n",
    "# 进行预测\n",
    "df['R_a_pre'] = ensemble_model.predict(input_features_scaled)\n",
    "\n",
    "# 计算 R_t_pre 列：R_a_pre 和 R_calm 的和\n",
    "df['R_t_pre'] = df['R_a_pre'] + df['R_calm']\n",
    "\n",
    "# 计算 P_pre 列\n",
    "df['P_pre'] = df.apply(Rtotal2Pe, axis=1)\n",
    "\n",
    "# 计算 Fuel_minutes 列\n",
    "df['Fuel_hour'] = df.apply(calFuelHour, axis=1)\n",
    "\n",
    "print(df['Fuel_hour'].sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
