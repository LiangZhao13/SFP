{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded saved parameters for XGBoost and CatBoost.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 107\u001b[0m\n\u001b[1;32m    104\u001b[0m ensemble_model \u001b[38;5;241m=\u001b[39m VotingRegressor([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m'\u001b[39m, xgb_model), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcatboost\u001b[39m\u001b[38;5;124m'\u001b[39m, catboost_model)])\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# 训练集成模型\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m \u001b[43mensemble_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# 使用集成模型预测\u001b[39;00m\n\u001b[1;32m    110\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m ensemble_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[1;32m     69\u001b[0m ]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/ensemble/_voting.py:701\u001b[0m, in \u001b[0;36mVotingRegressor.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    700\u001b[0m     fit_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[0;32m--> 701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/ensemble/_voting.py:81\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@abstractmethod\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get common fit operations.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     names, clfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_estimators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators):\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/ensemble/_base.py:233\u001b[0m, in \u001b[0;36m_BaseHeterogeneousEnsemble._validate_estimators\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m is_estimator_type \u001b[38;5;241m=\u001b[39m is_classifier \u001b[38;5;28;01mif\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m is_regressor\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m est \u001b[38;5;129;01min\u001b[39;00m estimators:\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_estimator_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe estimator \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m should be a \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    236\u001b[0m                 est\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_estimator_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m[\u001b[38;5;241m3\u001b[39m:]\n\u001b[1;32m    237\u001b[0m             )\n\u001b[1;32m    238\u001b[0m         )\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m names, estimators\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1277\u001b[0m, in \u001b[0;36mis_regressor\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing a class to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mprint\u001b[39m(inspect\u001b[38;5;241m.\u001b[39mstack()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in 1.8. Use an instance of the class instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1273\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1274\u001b[0m     )\n\u001b[1;32m   1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_estimator_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/_tags.py:405\u001b[0m, in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[0;32m--> 405\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py:613\u001b[0m, in \u001b[0;36mRegressorMixin.__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 613\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sklearn_tags__\u001b[49m()\n\u001b[1;32m    614\u001b[0m     tags\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    615\u001b[0m     tags\u001b[38;5;241m.\u001b[39mregressor_tags \u001b[38;5;241m=\u001b[39m RegressorTags()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "# 忽略所有警告\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 读取数据并预处理\n",
    "data = pd.read_csv('/workspaces/SFP/Training_data/data_13_17_1_std.csv')  # 替换为实际数据路径\n",
    "data = data.drop(['Unnamed: 0', 'Pe', 'R_total', 'R_calm', 'postime', 'num'], axis=1)\n",
    "\n",
    "# 数据清理：使用KMeans聚类检测异常值\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "data['cluster'] = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "# 假设较小的簇为异常数据\n",
    "cluster_sizes = data['cluster'].value_counts()\n",
    "anomaly_cluster = cluster_sizes.idxmin()\n",
    "data = data[data['cluster'] != anomaly_cluster]\n",
    "data = data.drop(columns=['cluster'])\n",
    "\n",
    "# 特征和目标提取\n",
    "features = data.drop(columns=['R_added']).values\n",
    "targets = data['R_added'].values\n",
    "\n",
    "# 特征标准化\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# 数据集划分\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "# 检查是否已有最佳参数保存\n",
    "try:\n",
    "    xgb_best_params = joblib.load(\"xgb_best_params.pkl\")\n",
    "    catboost_best_params = joblib.load(\"catboost_best_params.pkl\")\n",
    "    print(\"Loaded saved parameters for XGBoost and CatBoost.\")\n",
    "except FileNotFoundError:\n",
    "    # 定义Optuna优化目标函数（用于XGBoost）\n",
    "    def objective_xgb(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 1.0),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1, 10.0),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10)\n",
    "        }\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, **params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return rmse\n",
    "\n",
    "    # 定义Optuna优化目标函数（用于CatBoost）\n",
    "    def objective_catboost(trial):\n",
    "        params = {\n",
    "            'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "            'depth': trial.suggest_int('depth', 4, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
    "            'random_strength': trial.suggest_float('random_strength', 0, 1)\n",
    "        }\n",
    "        model = CatBoostRegressor(verbose=0, random_seed=42, **params)\n",
    "        model.fit(X_train, y_train, eval_set=(X_test, y_test))\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        return rmse\n",
    "\n",
    "    # 使用Optuna优化XGBoost超参数\n",
    "    study_xgb = optuna.create_study(direction='minimize', study_name='XGBoost Optimization')\n",
    "    study_xgb.optimize(objective_xgb, n_trials=50, show_progress_bar=False)\n",
    "\n",
    "    # 使用Optuna优化CatBoost超参数\n",
    "    study_catboost = optuna.create_study(direction='minimize', study_name='CatBoost Optimization')\n",
    "    study_catboost.optimize(objective_catboost, n_trials=50, show_progress_bar=False)\n",
    "\n",
    "    # 保存最佳参数\n",
    "    xgb_best_params = study_xgb.best_params\n",
    "    catboost_best_params = study_catboost.best_params\n",
    "    joblib.dump(xgb_best_params, \"xgb_best_params.pkl\")\n",
    "    joblib.dump(catboost_best_params, \"catboost_best_params.pkl\")\n",
    "    print(\"Saved best parameters for XGBoost and CatBoost.\")\n",
    "\n",
    "# 定义XGBoost和CatBoost模型\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, **xgb_best_params)\n",
    "catboost_model = CatBoostRegressor(verbose=0, random_seed=42, **catboost_best_params)\n",
    "\n",
    "# 集成模型：Voting Regressor\n",
    "ensemble_model = VotingRegressor([('xgb', xgb_model), ('catboost', catboost_model)])\n",
    "\n",
    "# 训练集成模型\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# 使用集成模型预测\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "# 计算评估指标\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "print(\"Root Mean Squared Error: \", rmse)\n",
    "print(\"R2 Score: \", r2)\n",
    "\n",
    "# 如果需要保存模型\n",
    "joblib.dump(ensemble_model, \"ensemble_model.pkl\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
